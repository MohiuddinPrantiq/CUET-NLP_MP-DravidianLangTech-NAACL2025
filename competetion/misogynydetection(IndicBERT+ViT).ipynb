{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10523956,"sourceType":"datasetVersion","datasetId":6404969}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom transformers import AutoModel, AutoTokenizer, ViTFeatureExtractor, ViTModel\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image \nimport torch.nn.functional as F\nfrom sklearn.metrics import f1_score\nimport numpy as np\nfrom tqdm import tqdm\nimport pandas as pd\nimport os\nprint('imported')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T18:38:12.157287Z","iopub.execute_input":"2025-01-20T18:38:12.157600Z","iopub.status.idle":"2025-01-20T18:38:12.162857Z","shell.execute_reply.started":"2025-01-20T18:38:12.157566Z","shell.execute_reply":"2025-01-20T18:38:12.161811Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_mal_train = pd.read_csv('/kaggle/input/misogyny/misogyny/misogyny/malayalam/train/train.csv')\ndf_mal_dev = pd.read_csv('/kaggle/input/misogyny/misogyny/misogyny/malayalam/dev/dev.csv')\ndf_mal_test = pd.read_csv('/kaggle/input/misogyny/misogyny/misogyny/malayalam/test/test.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T18:38:13.050297Z","iopub.execute_input":"2025-01-20T18:38:13.050648Z","iopub.status.idle":"2025-01-20T18:38:13.068931Z","shell.execute_reply.started":"2025-01-20T18:38:13.050619Z","shell.execute_reply":"2025-01-20T18:38:13.068069Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_mal_train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T18:38:13.929228Z","iopub.execute_input":"2025-01-20T18:38:13.929567Z","iopub.status.idle":"2025-01-20T18:38:13.938769Z","shell.execute_reply.started":"2025-01-20T18:38:13.929537Z","shell.execute_reply":"2025-01-20T18:38:13.937857Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_mal_train.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T18:38:14.724915Z","iopub.execute_input":"2025-01-20T18:38:14.725210Z","iopub.status.idle":"2025-01-20T18:38:14.731954Z","shell.execute_reply.started":"2025-01-20T18:38:14.725188Z","shell.execute_reply":"2025-01-20T18:38:14.731050Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_tam_train = pd.read_csv('/kaggle/input/misogyny/misogyny/misogyny/tamil/train/train.csv')\ndf_tam_dev = pd.read_csv('/kaggle/input/misogyny/misogyny/misogyny/tamil/dev/dev.csv')\ndf_tam_test = pd.read_csv('/kaggle/input/misogyny/misogyny/misogyny/tamil/test/test.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T18:38:15.459918Z","iopub.execute_input":"2025-01-20T18:38:15.460206Z","iopub.status.idle":"2025-01-20T18:38:15.478872Z","shell.execute_reply.started":"2025-01-20T18:38:15.460183Z","shell.execute_reply":"2025-01-20T18:38:15.478012Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_tam_train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T18:38:16.025102Z","iopub.execute_input":"2025-01-20T18:38:16.025429Z","iopub.status.idle":"2025-01-20T18:38:16.034800Z","shell.execute_reply.started":"2025-01-20T18:38:16.025399Z","shell.execute_reply":"2025-01-20T18:38:16.033882Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_tam_train.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T18:38:16.472003Z","iopub.execute_input":"2025-01-20T18:38:16.472289Z","iopub.status.idle":"2025-01-20T18:38:16.479005Z","shell.execute_reply.started":"2025-01-20T18:38:16.472265Z","shell.execute_reply":"2025-01-20T18:38:16.478175Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_data(text_path, image_dir, is_test=False):\n    \n    df = pd.read_csv(text_path)\n    \n    image_paths = [os.path.join(image_dir, f\"{img_id}.jpg\") for img_id in df['image_id']]\n    \n    if is_test:\n        labels = [0] * len(df)\n    else:\n        labels = df['labels'].tolist()\n    \n    return {\n        'texts': df['transcriptions'].tolist(),\n        'images': image_paths,\n        'labels': labels,\n        'image_ids': df['image_id'].tolist()\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T18:38:16.861604Z","iopub.execute_input":"2025-01-20T18:38:16.861896Z","iopub.status.idle":"2025-01-20T18:38:16.866779Z","shell.execute_reply.started":"2025-01-20T18:38:16.861874Z","shell.execute_reply":"2025-01-20T18:38:16.865741Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_and_preprocess_data(text_data, image_paths, labels, tokenizer, feature_extractor, batch_size=16, is_train=True):\n\n    class MemeDataset(Dataset):\n        def __init__(self, texts, image_paths, labels, tokenizer, feature_extractor):\n            self.texts = texts\n            self.image_paths = image_paths\n            self.labels = labels\n            self.tokenizer = tokenizer\n            self.feature_extractor = feature_extractor\n        \n        def __len__(self):\n            return len(self.texts)\n        \n        def __getitem__(self, idx):\n            text = str(self.texts[idx])\n            encoding = self.tokenizer(\n                text,\n                padding='max_length',\n                max_length=128,\n                truncation=True,\n                return_tensors='pt'\n            )\n            \n            try:\n                image = Image.open(self.image_paths[idx]).convert('RGB')\n                image_features = self.feature_extractor(\n                    images=image,\n                    return_tensors='pt'\n                )\n            except Exception as e:\n                print(f\"Error loading image {self.image_paths[idx]}: {str(e)}\")\n                image = Image.new('RGB', (224, 224), color='black')\n                image_features = self.feature_extractor(\n                    images=image,\n                    return_tensors='pt'\n                )\n            \n            return {\n                'input_ids': encoding['input_ids'].squeeze(),\n                'attention_mask': encoding['attention_mask'].squeeze(),\n                'pixel_values': image_features['pixel_values'].squeeze(),\n                'label': torch.tensor(self.labels[idx], dtype=torch.long)\n            }\n\n    dataset = MemeDataset(text_data, image_paths, labels, tokenizer, feature_extractor)\n    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=is_train)\n    return dataloader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T18:38:17.269399Z","iopub.execute_input":"2025-01-20T18:38:17.269745Z","iopub.status.idle":"2025-01-20T18:38:17.276776Z","shell.execute_reply.started":"2025-01-20T18:38:17.269720Z","shell.execute_reply":"2025-01-20T18:38:17.275979Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_model(device):\n\n    text_model = AutoModel.from_pretrained(\"ai4bharat/indic-bert\").to(device)\n    \n    image_model = ViTModel.from_pretrained(\"google/vit-base-patch16-224\").to(device)\n    \n    fusion_model = nn.Sequential(\n        nn.Linear(768 * 2, 512),\n        nn.ReLU(),\n        nn.Dropout(0.2),\n        nn.Linear(512, 1)\n    ).to(device)\n    \n    return text_model, image_model, fusion_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T18:38:17.693623Z","iopub.execute_input":"2025-01-20T18:38:17.693931Z","iopub.status.idle":"2025-01-20T18:38:17.698409Z","shell.execute_reply.started":"2025-01-20T18:38:17.693906Z","shell.execute_reply":"2025-01-20T18:38:17.697651Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def forward_pass(batch, text_model, image_model, fusion_model, device):\n\n    input_ids = batch['input_ids'].to(device)\n    attention_mask = batch['attention_mask'].to(device)\n    pixel_values = batch['pixel_values'].to(device)\n    \n    text_outputs = text_model(input_ids=input_ids, attention_mask=attention_mask)\n    text_embeddings = text_outputs.last_hidden_state[:, 0, :]\n    \n    image_outputs = image_model(pixel_values)\n    image_embeddings = image_outputs.last_hidden_state[:, 0, :]\n    \n    fused = torch.cat([text_embeddings, image_embeddings], dim=1)\n    output = fusion_model(fused)\n    \n    return output.squeeze()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T18:38:18.078143Z","iopub.execute_input":"2025-01-20T18:38:18.078504Z","iopub.status.idle":"2025-01-20T18:38:18.083701Z","shell.execute_reply.started":"2025-01-20T18:38:18.078437Z","shell.execute_reply":"2025-01-20T18:38:18.082597Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_epoch(text_model, image_model, fusion_model, train_loader, optimizer, criterion, device):\n\n    text_model.train()\n    image_model.train()\n    fusion_model.train()\n    \n    total_loss = 0\n    all_preds = []\n    all_labels = []\n    \n    for batch in tqdm(train_loader, desc=\"Training\"):\n        labels = batch['label'].to(device)\n        \n        optimizer.zero_grad()\n        outputs = forward_pass(batch, text_model, image_model, fusion_model, device)\n        loss = criterion(outputs, labels.float())\n        \n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item()\n        \n        preds = (torch.sigmoid(outputs) > 0.5).int().cpu().numpy()\n        all_preds.extend(preds)\n        all_labels.extend(labels.cpu().numpy())\n    avg_loss = total_loss / len(train_loader)\n    f1 = f1_score(all_labels, all_preds)\n    \n    return avg_loss, f1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T18:38:18.494017Z","iopub.execute_input":"2025-01-20T18:38:18.494303Z","iopub.status.idle":"2025-01-20T18:38:18.499952Z","shell.execute_reply.started":"2025-01-20T18:38:18.494281Z","shell.execute_reply":"2025-01-20T18:38:18.499032Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate(text_model, image_model, fusion_model, val_loader, criterion, device):\n\n    text_model.eval()\n    image_model.eval()\n    fusion_model.eval()\n    \n    total_loss = 0\n    all_preds = []\n    all_labels = []\n    \n    with torch.no_grad():\n        for batch in tqdm(val_loader, desc=\"Evaluating\"):\n            labels = batch['label'].to(device)\n            outputs = forward_pass(batch, text_model, image_model, fusion_model, device)\n            loss = criterion(outputs, labels.float())\n            \n            total_loss += loss.item()\n            \n            preds = (torch.sigmoid(outputs) > 0.5).int().cpu().numpy()\n            all_preds.extend(preds)\n            all_labels.extend(labels.cpu().numpy())\n    \n    avg_loss = total_loss / len(val_loader)\n    f1 = f1_score(all_labels, all_preds)\n    \n    return avg_loss, f1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T18:38:18.878586Z","iopub.execute_input":"2025-01-20T18:38:18.878914Z","iopub.status.idle":"2025-01-20T18:38:18.885646Z","shell.execute_reply.started":"2025-01-20T18:38:18.878888Z","shell.execute_reply":"2025-01-20T18:38:18.884405Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_predictions(text_model, image_model, fusion_model, test_loader, device):\n    text_model.eval()\n    image_model.eval()\n    fusion_model.eval()\n    \n    all_preds = []\n    all_probs = []\n    \n    with torch.no_grad():\n        for batch in tqdm(test_loader, desc=\"Generating predictions\"):\n            outputs = forward_pass(batch, text_model, image_model, fusion_model, device)\n            probabilities = torch.sigmoid(outputs)\n            predictions = (probabilities > 0.5).int()\n            \n            all_probs.extend(probabilities.cpu().numpy())\n            all_preds.extend(predictions.cpu().numpy())\n    \n    return all_preds, all_probs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T18:38:19.271549Z","iopub.execute_input":"2025-01-20T18:38:19.271883Z","iopub.status.idle":"2025-01-20T18:38:19.277307Z","shell.execute_reply.started":"2025-01-20T18:38:19.271854Z","shell.execute_reply":"2025-01-20T18:38:19.276241Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_model(train_text_path, train_image_dir, \n                val_text_path, val_image_dir,\n                test_text_path, test_image_dir,language,\n                num_epochs=5, batch_size=16, learning_rate=2e-5):\n\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f\"Using device: {device}\")\n    \n    print(\"Loading data...\")\n    train_data = load_data(train_text_path, train_image_dir, is_test=False)\n    val_data = load_data(val_text_path, val_image_dir, is_test=False)\n    test_data = load_data(test_text_path, test_image_dir, is_test=True)  # Note is_test=True\n    \n    print(\"Initializing models...\")\n    tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/indic-bert\")\n    feature_extractor = ViTFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224\")\n    \n    train_loader = load_and_preprocess_data(\n        train_data['texts'], train_data['images'], train_data['labels'],\n        tokenizer, feature_extractor, batch_size, is_train=True\n    )\n    val_loader = load_and_preprocess_data(\n        val_data['texts'], val_data['images'], val_data['labels'],\n        tokenizer, feature_extractor, batch_size, is_train=False\n    )\n    test_loader = load_and_preprocess_data(\n        test_data['texts'], test_data['images'], test_data['labels'],\n        tokenizer, feature_extractor, batch_size, is_train=False\n    )\n    \n    text_model, image_model, fusion_model = create_model(device)\n    \n    params = list(text_model.parameters()) + list(image_model.parameters()) + list(fusion_model.parameters())\n    optimizer = torch.optim.AdamW(params, lr=learning_rate)\n    criterion = nn.BCEWithLogitsLoss()\n    \n    best_val_f1 = 0\n    \n    for epoch in range(num_epochs):\n        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n        \n        train_loss, train_f1 = train_epoch(\n            text_model, image_model, fusion_model,\n            train_loader, optimizer, criterion, device\n        )\n        \n        val_loss, val_f1 = evaluate(\n            text_model, image_model, fusion_model,\n            val_loader, criterion, device\n        )\n        \n        print(f\"Train Loss: {train_loss:.4f}, Train F1: {train_f1:.4f}\")\n        print(f\"Val Loss: {val_loss:.4f}, Val F1: {val_f1:.4f}\")\n        \n        if val_f1 > best_val_f1:\n            best_val_f1 = val_f1\n            torch.save({\n                'text_model_state_dict': text_model.state_dict(),\n                'image_model_state_dict': image_model.state_dict(),\n                'fusion_model_state_dict': fusion_model.state_dict(),\n            }, 'best_model.pth')\n    \n    print(\"\\nGenerating test predictions...\")\n    checkpoint = torch.load('best_model.pth')\n    text_model.load_state_dict(checkpoint['text_model_state_dict'])\n    image_model.load_state_dict(checkpoint['image_model_state_dict'])\n    fusion_model.load_state_dict(checkpoint['fusion_model_state_dict'])\n    \n    predictions, probabilities = get_predictions(\n        text_model, image_model, fusion_model,\n        test_loader, device\n    )\n    \n    predictions_df = pd.DataFrame({\n        'image_id': test_data['image_ids'],\n        'predicted_label': predictions,\n        'probability': probabilities\n    })\n    \n    predictions_df.to_csv(f'predictions_{language}.csv', index=False)\n    print(f\"\\nPredictions saved to 'predictions_{language}.csv'\")\n\nif __name__ == \"__main__\":\n    # Kaggle paths\n    TRAIN_TEXT_PATH = '/kaggle/input/misogyny/misogyny/misogyny/malayalam/train/train.csv'\n    TRAIN_IMAGE_DIR = '/kaggle/input/misogyny/misogyny/misogyny/malayalam/train/memes'\n    \n    VAL_TEXT_PATH = '/kaggle/input/misogyny/misogyny/misogyny/malayalam/dev/dev.csv'\n    VAL_IMAGE_DIR = '/kaggle/input/misogyny/misogyny/misogyny/malayalam/dev/memes'\n    \n    TEST_TEXT_PATH = '/kaggle/input/misogyny/misogyny/misogyny/malayalam/test/test.csv'\n    TEST_IMAGE_DIR = '/kaggle/input/misogyny/misogyny/misogyny/malayalam/test/memes'\n    \n    # Train the model\n    train_model(\n        TRAIN_TEXT_PATH, TRAIN_IMAGE_DIR,\n        VAL_TEXT_PATH, VAL_IMAGE_DIR,\n        TEST_TEXT_PATH, TEST_IMAGE_DIR,\n        'malayalam'\n    )\n\n    TRAIN_TEXT_PATH = '/kaggle/input/misogyny/misogyny/misogyny/tamil/train/train.csv'\n    TRAIN_IMAGE_DIR = '/kaggle/input/misogyny/misogyny/misogyny/tamil/train/memes'\n    \n    VAL_TEXT_PATH = '/kaggle/input/misogyny/misogyny/misogyny/tamil/dev/dev.csv'\n    VAL_IMAGE_DIR = '/kaggle/input/misogyny/misogyny/misogyny/tamil/dev/memes'\n    \n    TEST_TEXT_PATH = '/kaggle/input/misogyny/misogyny/misogyny/tamil/test/test.csv'\n    TEST_IMAGE_DIR = '/kaggle/input/misogyny/misogyny/misogyny/tamil/test/memes'\n    \n    train_model(\n        TRAIN_TEXT_PATH, TRAIN_IMAGE_DIR,\n        VAL_TEXT_PATH, VAL_IMAGE_DIR,\n        TEST_TEXT_PATH, TEST_IMAGE_DIR,\n        'tamil'\n    )\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T18:38:31.756881Z","iopub.execute_input":"2025-01-20T18:38:31.757167Z","iopub.status.idle":"2025-01-20T18:48:18.721790Z","shell.execute_reply.started":"2025-01-20T18:38:31.757146Z","shell.execute_reply":"2025-01-20T18:48:18.721039Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tamil_pred=pd.read_csv('/kaggle/working/predictions_tamil.csv')\ntamil_pred","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T18:48:43.213267Z","iopub.execute_input":"2025-01-20T18:48:43.213586Z","iopub.status.idle":"2025-01-20T18:48:43.227416Z","shell.execute_reply.started":"2025-01-20T18:48:43.213561Z","shell.execute_reply":"2025-01-20T18:48:43.226323Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"malayalam_pred=pd.read_csv('/kaggle/working/predictions_malayalam.csv')\nmalayalam_pred","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T18:49:07.808577Z","iopub.execute_input":"2025-01-20T18:49:07.808918Z","iopub.status.idle":"2025-01-20T18:49:07.819626Z","shell.execute_reply.started":"2025-01-20T18:49:07.808888Z","shell.execute_reply":"2025-01-20T18:49:07.818806Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import zipfile\n\ntamil_filtered = tamil_pred[['image_id', 'predicted_label']]\nmalayalam_filtered = malayalam_pred[['image_id', 'predicted_label']]\n\ntamil_csv_path = 'tamil.csv'\ntamil_filtered.to_csv(tamil_csv_path, index=False, header=False)\n\nmalayalam_csv_path = 'malayalam.csv'\nmalayalam_filtered.to_csv(malayalam_csv_path, index=False, header=False)\n\nteam_name = \"CUET-NLP_MP\"\n\nzip_file_path = f\"{team_name}.zip\"\nwith zipfile.ZipFile(zip_file_path, 'w') as zipf:\n    zipf.write(tamil_csv_path, arcname=f\"{team_name}_tamil_run1.csv\")\n    zipf.write(malayalam_csv_path, arcname=f\"{team_name}_malayalam_run1.csv\")\n\nzip_file_path","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T18:49:31.459333Z","iopub.execute_input":"2025-01-20T18:49:31.459648Z","iopub.status.idle":"2025-01-20T18:49:31.476666Z","shell.execute_reply.started":"2025-01-20T18:49:31.459623Z","shell.execute_reply":"2025-01-20T18:49:31.475956Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#malayalam\nmal_labels = pd.read_csv('/kaggle/input/misogyny/test_with_labels_malayalam/test_with_labels.csv')\nf1 = f1_score(mal_labels['labels'], malayalam_pred['predicted_label'], average='macro') \nprint(f\"F1 Score: {f1:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T18:53:31.682914Z","iopub.execute_input":"2025-01-20T18:53:31.683228Z","iopub.status.idle":"2025-01-20T18:53:31.699302Z","shell.execute_reply.started":"2025-01-20T18:53:31.683204Z","shell.execute_reply":"2025-01-20T18:53:31.698402Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#tamil\ntam_labels = pd.read_csv('/kaggle/input/misogyny/test_with_labels_tamil/test_with_labels.csv')\nf1 = f1_score(tam_labels['labels'], tamil_pred['predicted_label'], average='macro') \nprint(f\"F1 Score: {f1:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T18:56:05.362298Z","iopub.execute_input":"2025-01-20T18:56:05.362661Z","iopub.status.idle":"2025-01-20T18:56:05.379252Z","shell.execute_reply.started":"2025-01-20T18:56:05.362630Z","shell.execute_reply":"2025-01-20T18:56:05.378353Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}